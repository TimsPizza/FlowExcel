"""
ç®€æ´çš„æ’ä»¶å¼æ€§èƒ½åˆ†æå™¨
æä¾›éä¾µå…¥å¼çš„æ€§èƒ½è®¡æ•°åŠŸèƒ½
"""

import time
import threading
from typing import Dict, Any, Optional
from dataclasses import dataclass, field


@dataclass
class NodeStats:
    """èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯"""

    node_id: str
    node_type: str
    execution_count: int = 0
    total_time_ms: float = 0.0
    min_time_ms: float = float("inf")
    max_time_ms: float = 0.0
    error_count: int = 0

    @property
    def avg_time_ms(self) -> float:
        return self.total_time_ms / max(1, self.execution_count)


@dataclass
class DataFrameConversionStats:
    """DataFrameè½¬æ¢ç»Ÿè®¡ä¿¡æ¯"""

    to_pandas_count: int = 0
    to_pandas_total_time_ms: float = 0.0
    to_pandas_total_rows: int = 0
    from_pandas_count: int = 0
    from_pandas_total_time_ms: float = 0.0
    from_pandas_total_rows: int = 0

    @property
    def to_pandas_avg_time_ms(self) -> float:
        return self.to_pandas_total_time_ms / max(1, self.to_pandas_count)

    @property
    def from_pandas_avg_time_ms(self) -> float:
        return self.from_pandas_total_time_ms / max(1, self.from_pandas_count)


@dataclass
class ExcelIOStats:
    """Excelæ–‡ä»¶IOç»Ÿè®¡ä¿¡æ¯"""

    read_count: int = 0
    read_total_time_ms: float = 0.0
    read_total_rows: int = 0
    read_total_size_bytes: int = 0

    @property
    def read_avg_time_ms(self) -> float:
        return self.read_total_time_ms / max(1, self.read_count)


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""

    hit_count: int = 0
    miss_count: int = 0

    @property
    def total_requests(self) -> int:
        return self.hit_count + self.miss_count

    @property
    def hit_rate(self) -> float:
        total = self.total_requests
        return self.hit_count / max(1, total)

    @property
    def miss_rate(self) -> float:
        return 1.0 - self.hit_rate


@dataclass
class BatchPreloadStats:
    """æ‰¹é‡é¢„åŠ è½½ç»Ÿè®¡ä¿¡æ¯"""

    session_count: int = 0  # é¢„åŠ è½½ä¼šè¯æ•°
    total_files: int = 0  # æ€»æ–‡ä»¶æ•°
    total_sheets: int = 0  # æ€»Sheetæ•°
    total_time_ms: float = 0.0  # æ€»æ—¶é—´
    total_rows: int = 0  # æ€»è¡Œæ•°
    successful_sheets: int = 0  # æˆåŠŸåŠ è½½çš„Sheetæ•°
    failed_sheets: int = 0  # å¤±è´¥çš„Sheetæ•°
    total_io_reduction: int = 0  # æ€»IOå‡å°‘é‡

    @property
    def avg_time_per_session_ms(self) -> float:
        return self.total_time_ms / max(1, self.session_count)

    @property
    def avg_time_per_sheet_ms(self) -> float:
        return self.total_time_ms / max(1, self.total_sheets)

    @property
    def success_rate(self) -> float:
        if self.total_sheets == 0:
            return 0.0
        return self.successful_sheets / self.total_sheets


class PerformanceAnalyzer:
    """
    é›†ä¸­ç®¡ç†çš„æ€§èƒ½åˆ†æå™¨
    æä¾›æ’ä»¶å¼çš„æ€§èƒ½ç›‘æ§èƒ½åŠ›
    """

    def __init__(self):
        self.enabled = True
        self._lock = threading.Lock()
        self._node_stats: Dict[str, NodeStats] = {}
        self._active_executions: Dict[str, float] = {}  # execution_id -> start_time
        self._execution_counter = 0

        # å…¨å±€ç»Ÿè®¡
        self.total_executions = 0
        self.total_errors = 0
        self.total_time_ms = 0.0

        # æ–°å¢çš„ç»Ÿè®¡ç±»å‹
        self._dataframe_conversion_stats = DataFrameConversionStats()
        self._excel_io_stats = ExcelIOStats()
        self._cache_stats = CacheStats()
        self._batch_preload_stats = BatchPreloadStats()

        # DataFrameè½¬æ¢æ“ä½œçš„æ´»è·ƒæ‰§è¡Œè¿½è¸ª
        self._active_dataframe_conversions: Dict[str, float] = {}
        self._active_excel_reads: Dict[str, float] = {}
        self._conversion_counter = 0
        self._excel_read_counter = 0

    def onStart(self, node_id: str, node_type: str) -> str:
        """
        èŠ‚ç‚¹å¼€å§‹æ‰§è¡Œ

        Args:
            node_id: èŠ‚ç‚¹ID
            node_type: èŠ‚ç‚¹ç±»å‹

        Returns:
            æ‰§è¡ŒIDï¼Œç”¨äºåç»­çš„onFinishè°ƒç”¨
        """
        if not self.enabled:
            return ""

        with self._lock:
            self._execution_counter += 1
            execution_id = f"{node_id}_{self._execution_counter}"
            self._active_executions[execution_id] = time.time()

            # ç¡®ä¿èŠ‚ç‚¹ç»Ÿè®¡å­˜åœ¨
            if node_id not in self._node_stats:
                self._node_stats[node_id] = NodeStats(
                    node_id=node_id, node_type=node_type
                )

        return execution_id

    def onFinish(self, execution_id: str, success: bool = True) -> Optional[float]:
        """
        èŠ‚ç‚¹æ‰§è¡Œå®Œæˆ

        Args:
            execution_id: æ‰§è¡ŒIDï¼ˆç”±onStartè¿”å›ï¼‰
            success: æ˜¯å¦æˆåŠŸæ‰§è¡Œ

        Returns:
            æ‰§è¡Œæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¦‚æœexecution_idæ— æ•ˆåˆ™è¿”å›None
        """
        if not self.enabled or not execution_id:
            return None

        with self._lock:
            if execution_id not in self._active_executions:
                return None

            start_time = self._active_executions.pop(execution_id)
            execution_time_ms = (time.time() - start_time) * 1000

            # ä»execution_idæå–node_id
            node_id = execution_id.rsplit("_", 1)[0]

            if node_id in self._node_stats:
                stats = self._node_stats[node_id]
                stats.execution_count += 1
                stats.total_time_ms += execution_time_ms
                stats.min_time_ms = min(stats.min_time_ms, execution_time_ms)
                stats.max_time_ms = max(stats.max_time_ms, execution_time_ms)

                if not success:
                    stats.error_count += 1

            # æ›´æ–°å…¨å±€ç»Ÿè®¡
            self.total_executions += 1
            self.total_time_ms += execution_time_ms
            if not success:
                self.total_errors += 1

            # æ€§èƒ½è­¦å‘Š
            if execution_time_ms > 1000:
                pass
                # print(f"PERF WARNING: Node {node_id} took {execution_time_ms:.2f}ms")

            return execution_time_ms

    def onError(self, execution_id: str, error: Exception):
        """
        èŠ‚ç‚¹æ‰§è¡Œå‡ºé”™

        Args:
            execution_id: æ‰§è¡ŒID
            error: é”™è¯¯ä¿¡æ¯
        """
        execution_time = self.onFinish(execution_id, success=False)
        if execution_time is not None:
            node_id = execution_id.rsplit("_", 1)[0] if execution_id else "unknown"

    # DataFrameè½¬æ¢æ€§èƒ½è®¡æ•°hook
    def onDataFrameToPandasStart(self, row_count: int = None) -> str:
        """
        DataFrame.to_pandas()è½¬æ¢å¼€å§‹

        Args:
            row_count: DataFrameè¡Œæ•°ï¼ˆå¯é€‰ï¼‰

        Returns:
            è½¬æ¢ID
        """
        if not self.enabled:
            return ""

        with self._lock:
            self._conversion_counter += 1
            conversion_id = f"to_pandas_{self._conversion_counter}"
            self._active_dataframe_conversions[conversion_id] = time.time()

        return conversion_id

    def onDataFrameToPandasFinish(self, conversion_id: str, row_count: int = None):
        """
        DataFrame.to_pandas()è½¬æ¢å®Œæˆ

        Args:
            conversion_id: è½¬æ¢ID
            row_count: DataFrameè¡Œæ•°
        """
        if not self.enabled or not conversion_id:
            return

        with self._lock:
            if conversion_id not in self._active_dataframe_conversions:
                return

            start_time = self._active_dataframe_conversions.pop(conversion_id)
            conversion_time_ms = (time.time() - start_time) * 1000

            self._dataframe_conversion_stats.to_pandas_count += 1
            self._dataframe_conversion_stats.to_pandas_total_time_ms += (
                conversion_time_ms
            )
            if row_count:
                self._dataframe_conversion_stats.to_pandas_total_rows += row_count

            # æ€§èƒ½è­¦å‘Š
            if conversion_time_ms > 100:
                pass
                # print(
                #     f"PERF WARNING: DataFrame.to_pandas() took {conversion_time_ms:.2f}ms for {row_count or 'unknown'} rows"
                # )

    def onDataFrameFromPandasStart(self, row_count: int = None) -> str:
        """
        DataFrame.from_pandas()è½¬æ¢å¼€å§‹

        Args:
            row_count: pandas DataFrameè¡Œæ•°ï¼ˆå¯é€‰ï¼‰

        Returns:
            è½¬æ¢ID
        """
        if not self.enabled:
            return ""

        with self._lock:
            self._conversion_counter += 1
            conversion_id = f"from_pandas_{self._conversion_counter}"
            self._active_dataframe_conversions[conversion_id] = time.time()

        return conversion_id

    def onDataFrameFromPandasFinish(self, conversion_id: str, row_count: int = None):
        """
        DataFrame.from_pandas()è½¬æ¢å®Œæˆ

        Args:
            conversion_id: è½¬æ¢ID
            row_count: pandas DataFrameè¡Œæ•°
        """
        if not self.enabled or not conversion_id:
            return

        with self._lock:
            if conversion_id not in self._active_dataframe_conversions:
                return

            start_time = self._active_dataframe_conversions.pop(conversion_id)
            conversion_time_ms = (time.time() - start_time) * 1000

            self._dataframe_conversion_stats.from_pandas_count += 1
            self._dataframe_conversion_stats.from_pandas_total_time_ms += (
                conversion_time_ms
            )
            if row_count:
                self._dataframe_conversion_stats.from_pandas_total_rows += row_count

            # æ€§èƒ½è­¦å‘Š
            if conversion_time_ms > 100:
                pass
                # print(
                #     f"PERF WARNING: DataFrame.from_pandas() took {conversion_time_ms:.2f}ms for {row_count or 'unknown'} rows"
                # )

    # Excel IOæ€§èƒ½è®¡æ•°hook
    def onExcelReadStart(self, file_path: str, sheet_name: str = None) -> str:
        """
        Excelæ–‡ä»¶è¯»å–å¼€å§‹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            sheet_name: Sheetåç§°ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¯»å–ID
        """
        if not self.enabled:
            return ""

        with self._lock:
            self._excel_read_counter += 1
            read_id = f"excel_read_{self._excel_read_counter}"
            self._active_excel_reads[read_id] = time.time()

        return read_id

    def onExcelReadFinish(
        self, read_id: str, row_count: int = None, file_size_bytes: int = None
    ):
        """
        Excelæ–‡ä»¶è¯»å–å®Œæˆ

        Args:
            read_id: è¯»å–ID
            row_count: è¯»å–çš„è¡Œæ•°
            file_size_bytes: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        if not self.enabled or not read_id:
            return

        with self._lock:
            if read_id not in self._active_excel_reads:
                return

            start_time = self._active_excel_reads.pop(read_id)
            read_time_ms = (time.time() - start_time) * 1000

            self._excel_io_stats.read_count += 1
            self._excel_io_stats.read_total_time_ms += read_time_ms
            if row_count:
                self._excel_io_stats.read_total_rows += row_count
            if file_size_bytes:
                self._excel_io_stats.read_total_size_bytes += file_size_bytes

            # æ€§èƒ½è­¦å‘Š
            if read_time_ms > 500:
                # print(
                #     f"PERF WARNING: Excel read took {read_time_ms:.2f}ms for {row_count or 'unknown'} rows"
                # )
                pass

    # ç¼“å­˜æ€§èƒ½è®¡æ•°hook
    def onCacheHit(self, cache_key: str = None):
        """
        ç¼“å­˜å‘½ä¸­

        Args:
            cache_key: ç¼“å­˜é”®ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        """
        if not self.enabled:
            return

        with self._lock:
            self._cache_stats.hit_count += 1

    def onCacheMiss(self, cache_key: str = None):
        """
        ç¼“å­˜æœªå‘½ä¸­

        Args:
            cache_key: ç¼“å­˜é”®ï¼ˆå¯é€‰ï¼Œç”¨äºè°ƒè¯•ï¼‰
        """
        if not self.enabled:
            return

        with self._lock:
            self._cache_stats.miss_count += 1

    def onBatchPreloadComplete(
        self,
        total_files: int,
        total_sheets: int,
        successful_sheets: int,
        failed_sheets: int,
        total_time_ms: float,
        total_rows: int,
        total_io_reduction: int,
    ):
        """
        è®°å½•æ‰¹é‡é¢„åŠ è½½å®Œæˆ

        Args:
            total_files: æ€»æ–‡ä»¶æ•°
            total_sheets: æ€»Sheetæ•°
            successful_sheets: æˆåŠŸåŠ è½½çš„Sheetæ•°
            failed_sheets: å¤±è´¥çš„Sheetæ•°
            total_time_ms: æ€»æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            total_rows: æ€»è¡Œæ•°
        """
        if not self.enabled:
            return

        with self._lock:
            self._batch_preload_stats.session_count += 1
            self._batch_preload_stats.total_files += total_files
            self._batch_preload_stats.total_sheets += total_sheets
            self._batch_preload_stats.successful_sheets += successful_sheets
            self._batch_preload_stats.failed_sheets += failed_sheets
            self._batch_preload_stats.total_time_ms += total_time_ms
            self._batch_preload_stats.total_rows += total_rows
            self._batch_preload_stats.total_io_reduction += total_io_reduction

    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            return {
                "total_executions": self.total_executions,
                "total_time_ms": self.total_time_ms,
                "total_errors": self.total_errors,
                "avg_time_per_execution_ms": self.total_time_ms
                / max(1, self.total_executions),
                "error_rate": self.total_errors / max(1, self.total_executions),
                "active_executions": len(self._active_executions),
                "node_stats": {
                    node_id: {
                        "node_type": stats.node_type,
                        "execution_count": stats.execution_count,
                        "total_time_ms": stats.total_time_ms,
                        "avg_time_ms": stats.avg_time_ms,
                        "min_time_ms": (
                            stats.min_time_ms
                            if stats.min_time_ms != float("inf")
                            else 0
                        ),
                        "max_time_ms": stats.max_time_ms,
                        "error_count": stats.error_count,
                        "error_rate": stats.error_count / max(1, stats.execution_count),
                    }
                    for node_id, stats in self._node_stats.items()
                },
                "dataframe_conversion_stats": {
                    "to_pandas_count": self._dataframe_conversion_stats.to_pandas_count,
                    "to_pandas_total_time_ms": self._dataframe_conversion_stats.to_pandas_total_time_ms,
                    "to_pandas_avg_time_ms": self._dataframe_conversion_stats.to_pandas_avg_time_ms,
                    "to_pandas_total_rows": self._dataframe_conversion_stats.to_pandas_total_rows,
                    "from_pandas_count": self._dataframe_conversion_stats.from_pandas_count,
                    "from_pandas_total_time_ms": self._dataframe_conversion_stats.from_pandas_total_time_ms,
                    "from_pandas_avg_time_ms": self._dataframe_conversion_stats.from_pandas_avg_time_ms,
                    "from_pandas_total_rows": self._dataframe_conversion_stats.from_pandas_total_rows,
                },
                "excel_io_stats": {
                    "read_count": self._excel_io_stats.read_count,
                    "read_total_time_ms": self._excel_io_stats.read_total_time_ms,
                    "read_avg_time_ms": self._excel_io_stats.read_avg_time_ms,
                    "read_total_rows": self._excel_io_stats.read_total_rows,
                    "read_total_size_bytes": self._excel_io_stats.read_total_size_bytes,
                },
                "cache_stats": {
                    "hit_count": self._cache_stats.hit_count,
                    "miss_count": self._cache_stats.miss_count,
                    "total_requests": self._cache_stats.total_requests,
                    "hit_rate": self._cache_stats.hit_rate,
                    "miss_rate": self._cache_stats.miss_rate,
                },
                "batch_preload_stats": {
                    "session_count": self._batch_preload_stats.session_count,
                    "total_files": self._batch_preload_stats.total_files,
                    "total_sheets": self._batch_preload_stats.total_sheets,
                    "successful_sheets": self._batch_preload_stats.successful_sheets,
                    "failed_sheets": self._batch_preload_stats.failed_sheets,
                    "total_time_ms": self._batch_preload_stats.total_time_ms,
                    "total_rows": self._batch_preload_stats.total_rows,
                    "avg_time_per_session_ms": self._batch_preload_stats.avg_time_per_session_ms,
                    "avg_time_per_sheet_ms": self._batch_preload_stats.avg_time_per_sheet_ms,
                    "success_rate": self._batch_preload_stats.success_rate,
                    "total_io_reduction": self._batch_preload_stats.total_io_reduction,
                },
            }

    def print_stats(self):
        return
        # æš‚æ—¶å…³é—­æ€§èƒ½ç»Ÿè®¡
        """æ‰“å°æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()

        print("=" * 60)
        print("æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        print(f"ğŸ“Š æ€»æ‰§è¡Œæ¬¡æ•°: {stats['total_executions']}")
        print(f"â±ï¸  æ€»æ‰§è¡Œæ—¶é—´: {stats['total_time_ms']:.2f}ms")
        print(f"ğŸ“ˆ å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_time_per_execution_ms']:.2f}ms")
        print(f"âŒ é”™è¯¯æ¬¡æ•°: {stats['total_errors']}")
        print(f"ğŸ“‰ é”™è¯¯ç‡: {stats['error_rate']:.2%}")
        print(f"ğŸ”„ æ´»è·ƒæ‰§è¡Œ: {stats['active_executions']}")
        print()

        # DataFrameè½¬æ¢ç»Ÿè®¡
        df_stats = stats["dataframe_conversion_stats"]
        if df_stats["to_pandas_count"] > 0 or df_stats["from_pandas_count"] > 0:
            print("DataFrameè½¬æ¢ç»Ÿè®¡:")
            print("-" * 30)
            print(f"ğŸ”„ to_pandas()è°ƒç”¨: {df_stats['to_pandas_count']}")
            print(f"â±ï¸  to_pandas()æ€»æ—¶é—´: {df_stats['to_pandas_total_time_ms']:.2f}ms")
            print(f"ğŸ“Š to_pandas()å¹³å‡æ—¶é—´: {df_stats['to_pandas_avg_time_ms']:.2f}ms")
            print(f"ğŸ“‹ to_pandas()æ€»è¡Œæ•°: {df_stats['to_pandas_total_rows']}")
            print(f"ğŸ”„ from_pandas()è°ƒç”¨: {df_stats['from_pandas_count']}")
            print(
                f"â±ï¸  from_pandas()æ€»æ—¶é—´: {df_stats['from_pandas_total_time_ms']:.2f}ms"
            )
            print(
                f"ğŸ“Š from_pandas()å¹³å‡æ—¶é—´: {df_stats['from_pandas_avg_time_ms']:.2f}ms"
            )
            print(f"ğŸ“‹ from_pandas()æ€»è¡Œæ•°: {df_stats['from_pandas_total_rows']}")
            print()

        # Excel IOç»Ÿè®¡
        excel_stats = stats["excel_io_stats"]
        if excel_stats["read_count"] > 0:
            print("Excelæ–‡ä»¶IOç»Ÿè®¡(æ‰¹é‡é¢„åŠ è½½ä¹‹å¤–):")
            print("-" * 30)
            print(f"ğŸ“– æ–‡ä»¶è¯»å–æ¬¡æ•°: {excel_stats['read_count']}")
            print(f"â±ï¸  è¯»å–æ€»æ—¶é—´: {excel_stats['read_total_time_ms']:.2f}ms")
            print(f"ğŸ“Š å¹³å‡è¯»å–æ—¶é—´: {excel_stats['read_avg_time_ms']:.2f}ms")
            print(f"ğŸ“‹ è¯»å–æ€»è¡Œæ•°: {excel_stats['read_total_rows']}")
            print(f"ğŸ’¾ è¯»å–æ€»å¤§å°: {excel_stats['read_total_size_bytes']} bytes")
            print()

        # ç¼“å­˜ç»Ÿè®¡
        cache_stats = stats["cache_stats"]
        if cache_stats["total_requests"] > 0:
            print("ç¼“å­˜æ€§èƒ½ç»Ÿè®¡:")
            print("-" * 30)
            print(f"âœ… ç¼“å­˜å‘½ä¸­: {cache_stats['hit_count']}")
            print(f"âŒ ç¼“å­˜æœªå‘½ä¸­: {cache_stats['miss_count']}")
            print(f"ğŸ“Š æ€»è¯·æ±‚æ•°: {cache_stats['total_requests']}")
            print(f"ğŸ“ˆ å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2%}")
            print(f"ğŸ“‰ æœªå‘½ä¸­ç‡: {cache_stats['miss_rate']:.2%}")
            print()

        # æ‰¹é‡é¢„åŠ è½½ç»Ÿè®¡
        batch_stats = stats["batch_preload_stats"]
        if batch_stats is not None:
            print("æ‰¹é‡é¢„åŠ è½½ç»Ÿè®¡:")
            print("-" * 30)
            print(f"ğŸš€ é¢„åŠ è½½ä¼šè¯: {batch_stats['session_count']}")
            print(f"ğŸ“ æ€»æ–‡ä»¶æ•°: {batch_stats['total_files']}")
            print(f"ğŸ“„ æ€»Sheetæ•°: {batch_stats['total_sheets']}")
            print(f"âœ… æˆåŠŸåŠ è½½: {batch_stats['successful_sheets']}")
            print(f"âŒ åŠ è½½å¤±è´¥: {batch_stats['failed_sheets']}")
            print(f"â±ï¸  é¢„åŠ è½½æ€»æ—¶é—´: {batch_stats['total_time_ms']:.2f}ms")
            print(f"ğŸ“‹ é¢„åŠ è½½æ€»è¡Œæ•°: {batch_stats['total_rows']}")
            print(f"ğŸ“Š å¹³å‡ä¼šè¯æ—¶é—´: {batch_stats['avg_time_per_session_ms']:.2f}ms")
            print(f"ğŸ“ˆ æˆåŠŸç‡: {batch_stats['success_rate']:.2%}")
            print(f"ğŸ“Š æ€»IOå‡å°‘é‡: {batch_stats['total_io_reduction']}")
            print()

        if stats["node_stats"]:
            print("å„èŠ‚ç‚¹è¯¦ç»†ç»Ÿè®¡:")
            print("-" * 60)
            for node_id, node_stats in stats["node_stats"].items():
                print(f"ğŸ”¹ {node_stats['node_type']} ({node_id}):")
                print(f"   æ‰§è¡Œæ¬¡æ•°: {node_stats['execution_count']}")
                print(f"   å¹³å‡æ—¶é—´: {node_stats['avg_time_ms']:.2f}ms")
                print(
                    f"   æ—¶é—´èŒƒå›´: {node_stats['min_time_ms']:.2f}ms - {node_stats['max_time_ms']:.2f}ms"
                )
                print(
                    f"   é”™è¯¯æ¬¡æ•°: {node_stats['error_count']} ({node_stats['error_rate']:.1%})"
                )
                print()
        print("=" * 60)

    def reset(self):
        """é‡ç½®æ‰€æœ‰æ€§èƒ½æ•°æ®"""
        with self._lock:
            self._node_stats.clear()
            self._active_executions.clear()
            self._active_dataframe_conversions.clear()
            self._active_excel_reads.clear()
            self._execution_counter = 0
            self._conversion_counter = 0
            self._excel_read_counter = 0
            self.total_executions = 0
            self.total_errors = 0
            self.total_time_ms = 0.0

            # é‡ç½®æ–°çš„ç»Ÿè®¡æ•°æ®
            self._dataframe_conversion_stats = DataFrameConversionStats()
            self._excel_io_stats = ExcelIOStats()
            self._cache_stats = CacheStats()
            self._batch_preload_stats = BatchPreloadStats()

        print("PERF: æ€§èƒ½ç»Ÿè®¡å·²é‡ç½®")

    def enable(self):
        """å¯ç”¨æ€§èƒ½ç›‘æ§"""
        self.enabled = True

    def disable(self):
        """ç¦ç”¨æ€§èƒ½ç›‘æ§"""
        self.enabled = False


# å…¨å±€æ€§èƒ½åˆ†æå™¨å®ä¾‹
_global_analyzer = PerformanceAnalyzer()


def get_performance_analyzer() -> PerformanceAnalyzer:
    """è·å–å…¨å±€æ€§èƒ½åˆ†æå™¨å®ä¾‹"""
    return _global_analyzer
